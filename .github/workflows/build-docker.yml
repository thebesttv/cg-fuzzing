name: Build Docker Images

on:
  push:
  workflow_dispatch:

env:
  DOCKER_HUB_USERNAME: thebesttv

# Permissions for artifacts and releases
permissions:
  contents: write

defaults:
  run:
    working-directory: ./dataset

jobs:
  find-projects:
    runs-on: ubuntu-latest
    outputs:
      projects: ${{ steps.find.outputs.projects }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Find projects with dockerfiles
        id: find
        run: |
          # Find all unique project directories containing any dockerfile
          # (bc.dockerfile, fuzz.dockerfile, cov.dockerfile, uftrace.dockerfile)
          projects=$(find . -maxdepth 2 -type f \( -name "bc.dockerfile" -o -name "fuzz.dockerfile" -o -name "cov.dockerfile" -o -name "uftrace.dockerfile" \) ! -path "./.git/*" \
            | xargs -I{} dirname {} \
            | sed 's|^\./||' \
            | sort -u \
            | jq -R -s -c 'split("\n") | map(select(length > 0))')

          echo "projects=${projects}" >> $GITHUB_OUTPUT
          echo "Found projects: ${projects}"

  get-changed-projects:
    needs: find-projects
    runs-on: ubuntu-latest
    outputs:
      projects: ${{ steps.set-projects.outputs.projects || steps.set-projects-pr.outputs.projects }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Detect changed dataset files
        id: changes
        uses: dorny/paths-filter@v3
        with:
          filters: |
            dataset:
              - 'dataset/**'
          list-files: json

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Set projects for default branch
        id: set-projects
        if: github.ref == format('refs/heads/{0}', github.event.repository.default_branch)
        run: |
          echo "Default branch detected - pairing all projects"
          ALL_PROJECTS='${{ needs.find-projects.outputs.projects }}'
          
          # For default branch, create a fake "all files changed" JSON to reuse the Python script
          # Generate a list like ["dataset/proj1/file", "dataset/proj2/file", ...]
          FAKE_FILES=$(echo "$ALL_PROJECTS" | jq -c 'map("dataset/" + . + "/dummy")')
          
          # Use Python script to pair all projects
          PAIRED=$(python3 .github/scripts/compute_changed_projects.py "$FAKE_FILES" "$ALL_PROJECTS")
          echo "projects=$PAIRED" >> $GITHUB_OUTPUT
          echo "Paired projects: $PAIRED"

      - name: Compute changed projects
        id: set-projects-pr
        if: github.ref != format('refs/heads/{0}', github.event.repository.default_branch)
        run: |
          FILES='${{ steps.changes.outputs.dataset_files }}'
          if [ -z "$FILES" ] || [ "$FILES" = "[]" ]; then
            echo "No dataset files changed"
            echo "projects=[]" >> $GITHUB_OUTPUT
            exit 0
          fi

          ALL='${{ needs.find-projects.outputs.projects }}'
          
          # Use Python script to compute changed projects and pair them
          PAIRED=$(python3 .github/scripts/compute_changed_projects.py "$FILES" "$ALL")
          echo "projects=$PAIRED" >> $GITHUB_OUTPUT
          echo "Paired projects: $PAIRED"

  build-project:
    needs: get-changed-projects
    if: ${{ needs.get-changed-projects.outputs.projects != '[]' && needs.get-changed-projects.outputs.projects != 'null' }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        pair: ${{ fromJson(needs.get-changed-projects.outputs.projects) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Validate project names
        run: |
          # Validate both project names contain only safe characters
          for proj in "${{ matrix.pair.proj1 }}" "${{ matrix.pair.proj2 }}"; do
            if ! echo "$proj" | grep -qE '^[a-zA-Z0-9_-]+$'; then
              echo "Error: Invalid project name: $proj"
              exit 1
            fi
          done

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Create output directories
        run: |
          mkdir -p output/${{ matrix.pair.proj1 }}/{bc,fuzz}
          mkdir -p output/${{ matrix.pair.proj2 }}/{bc,fuzz}

      # Build proj1 - bc
      - name: Build bc.dockerfile for ${{ matrix.pair.proj1 }}
        id: build-bc-proj1
        run: |
          if [ -f "${{ matrix.pair.proj1 }}/bc.dockerfile" ]; then
            echo "Building ${{ matrix.pair.proj1 }}-bc from ${{ matrix.pair.proj1 }}/bc.dockerfile"
            docker build \
              -f "${{ matrix.pair.proj1 }}/bc.dockerfile" \
              -t "${{ matrix.pair.proj1 }}-bc:latest" \
              .
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "bc.dockerfile not found for ${{ matrix.pair.proj1 }}"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Extract bc artifacts for ${{ matrix.pair.proj1 }}
        if: steps.build-bc-proj1.outputs.exists == 'true'
        run: |
          container_id=$(docker create "${{ matrix.pair.proj1 }}-bc:latest")
          # Copy bc files from container
          docker cp "$container_id:/home/SVF-tools/bc/." "output/${{ matrix.pair.proj1 }}/bc/" 2>/dev/null || true
          docker rm "$container_id"
          echo "=== bc artifacts for ${{ matrix.pair.proj1 }} ==="
          ls -la "output/${{ matrix.pair.proj1 }}/bc/" || true
          # Verify directory is non-empty
          if [ -z "$(ls -A "output/${{ matrix.pair.proj1 }}/bc/" 2>/dev/null)" ]; then
            echo "Error: bc artifacts directory is empty!"
            exit 1
          fi

      # Build proj1 - fuzz
      - name: Build fuzz.dockerfile for ${{ matrix.pair.proj1 }}
        id: build-fuzz-proj1
        run: |
          if [ -f "${{ matrix.pair.proj1 }}/fuzz.dockerfile" ]; then
            echo "Building ${{ matrix.pair.proj1 }}-fuzz from ${{ matrix.pair.proj1 }}/fuzz.dockerfile"
            docker build \
              -f "${{ matrix.pair.proj1 }}/fuzz.dockerfile" \
              -t "${{ matrix.pair.proj1 }}-fuzz:latest" \
              .
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "fuzz.dockerfile not found for ${{ matrix.pair.proj1 }}"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Extract fuzz artifacts for ${{ matrix.pair.proj1 }}
        if: steps.build-fuzz-proj1.outputs.exists == 'true'
        run: |
          container_id=$(docker create "${{ matrix.pair.proj1 }}-fuzz:latest")
          if docker cp "$container_id:/work/." "output/${{ matrix.pair.proj1 }}/fuzz/" 2>/dev/null; then
            echo "Successfully copied artifacts from /work"
          else
            echo "/work not found"
            exit 1
          fi
          docker rm "$container_id"
          echo "=== fuzz artifacts for ${{ matrix.pair.proj1 }} ==="
          ls -la "output/${{ matrix.pair.proj1 }}/fuzz/" || true
          # Verify directory is non-empty
          if [ -z "$(ls -A "output/${{ matrix.pair.proj1 }}/fuzz/" 2>/dev/null)" ]; then
            echo "Error: fuzz artifacts directory is empty!"
            exit 1
          fi

      # Build proj2 - bc
      - name: Build bc.dockerfile for ${{ matrix.pair.proj2 }}
        id: build-bc-proj2
        run: |
          if [ -f "${{ matrix.pair.proj2 }}/bc.dockerfile" ]; then
            echo "Building ${{ matrix.pair.proj2 }}-bc from ${{ matrix.pair.proj2 }}/bc.dockerfile"
            docker build \
              -f "${{ matrix.pair.proj2 }}/bc.dockerfile" \
              -t "${{ matrix.pair.proj2 }}-bc:latest" \
              .
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "bc.dockerfile not found for ${{ matrix.pair.proj2 }}"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Extract bc artifacts for ${{ matrix.pair.proj2 }}
        if: steps.build-bc-proj2.outputs.exists == 'true'
        run: |
          container_id=$(docker create "${{ matrix.pair.proj2 }}-bc:latest")
          # Copy bc files from container
          docker cp "$container_id:/home/SVF-tools/bc/." "output/${{ matrix.pair.proj2 }}/bc/" 2>/dev/null || true
          docker rm "$container_id"
          echo "=== bc artifacts for ${{ matrix.pair.proj2 }} ==="
          ls -la "output/${{ matrix.pair.proj2 }}/bc/" || true
          # Verify directory is non-empty
          if [ -z "$(ls -A "output/${{ matrix.pair.proj2 }}/bc/" 2>/dev/null)" ]; then
            echo "Error: bc artifacts directory is empty!"
            exit 1
          fi

      # Build proj2 - fuzz
      - name: Build fuzz.dockerfile for ${{ matrix.pair.proj2 }}
        id: build-fuzz-proj2
        run: |
          if [ -f "${{ matrix.pair.proj2 }}/fuzz.dockerfile" ]; then
            echo "Building ${{ matrix.pair.proj2 }}-fuzz from ${{ matrix.pair.proj2 }}/fuzz.dockerfile"
            docker build \
              -f "${{ matrix.pair.proj2 }}/fuzz.dockerfile" \
              -t "${{ matrix.pair.proj2 }}-fuzz:latest" \
              .
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "fuzz.dockerfile not found for ${{ matrix.pair.proj2 }}"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Extract fuzz artifacts for ${{ matrix.pair.proj2 }}
        if: steps.build-fuzz-proj2.outputs.exists == 'true'
        run: |
          container_id=$(docker create "${{ matrix.pair.proj2 }}-fuzz:latest")
          if docker cp "$container_id:/work/." "output/${{ matrix.pair.proj2 }}/fuzz/" 2>/dev/null; then
            echo "Successfully copied artifacts from /work"
          else
            echo "/work not found"
            exit 1
          fi
          docker rm "$container_id"
          echo "=== fuzz artifacts for ${{ matrix.pair.proj2 }} ==="
          ls -la "output/${{ matrix.pair.proj2 }}/fuzz/" || true
          # Verify directory is non-empty
          if [ -z "$(ls -A "output/${{ matrix.pair.proj2 }}/fuzz/" 2>/dev/null)" ]; then
            echo "Error: fuzz artifacts directory is empty!"
            exit 1
          fi

      - name: Remove empty directories
        run: |
          # Remove empty subdirectories from output
          find "output/${{ matrix.pair.proj1 }}" -type d -empty -delete 2>/dev/null || true
          find "output/${{ matrix.pair.proj2 }}" -type d -empty -delete 2>/dev/null || true
          echo "=== Final output structure ==="
          find "output/${{ matrix.pair.proj1 }}" -type f | head -50
          find "output/${{ matrix.pair.proj2 }}" -type f | head -50

      - name: Create project archives with tar.xz
        run: |
          cd output
          # Create archive for proj1
          XZ_OPT="-9e -T0" tar -cJf "${{ matrix.pair.proj1 }}.tar.xz" "${{ matrix.pair.proj1 }}"
          ls -lh "${{ matrix.pair.proj1 }}.tar.xz"
          
          # Create archive for proj2 (skip if same as proj1)
          if [ "${{ matrix.pair.proj1 }}" != "${{ matrix.pair.proj2 }}" ]; then
            XZ_OPT="-9e -T0" tar -cJf "${{ matrix.pair.proj2 }}.tar.xz" "${{ matrix.pair.proj2 }}"
            ls -lh "${{ matrix.pair.proj2 }}.tar.xz"
          fi

      - name: Upload artifact for ${{ matrix.pair.proj1 }}
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.pair.proj1 }}
          path: dataset/output/${{ matrix.pair.proj1 }}.tar.xz
          retention-days: 30

      - name: Upload artifact for ${{ matrix.pair.proj2 }}
        if: matrix.pair.proj1 != matrix.pair.proj2
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.pair.proj2 }}
          path: dataset/output/${{ matrix.pair.proj2 }}.tar.xz
          retention-days: 30

      - name: Login to Docker Hub
        if: github.ref == format('refs/heads/{0}', github.event.repository.default_branch) && github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          username: ${{ env.DOCKER_HUB_USERNAME }}
          password: ${{ secrets.DOCKER_HUB_TOKEN }}

      - name: Push Docker images to Docker Hub
        if: github.ref == format('refs/heads/{0}', github.event.repository.default_branch) && github.event_name != 'pull_request'
        run: |
          # Push images for proj1
          for type in bc fuzz; do
            image="${{ matrix.pair.proj1 }}-${type}"
            if docker image inspect "${image}:latest" >/dev/null 2>&1; then
              echo "Pushing ${{ env.DOCKER_HUB_USERNAME }}/${image}:latest"
              docker tag "${image}:latest" "${{ env.DOCKER_HUB_USERNAME }}/${image}:latest"
              docker push "${{ env.DOCKER_HUB_USERNAME }}/${image}:latest"
            fi
          done
          
          # Push images for proj2 (skip if same as proj1)
          if [ "${{ matrix.pair.proj1 }}" != "${{ matrix.pair.proj2 }}" ]; then
            for type in bc fuzz; do
              image="${{ matrix.pair.proj2 }}-${type}"
              if docker image inspect "${image}:latest" >/dev/null 2>&1; then
                echo "Pushing ${{ env.DOCKER_HUB_USERNAME }}/${image}:latest"
                docker tag "${image}:latest" "${{ env.DOCKER_HUB_USERNAME }}/${image}:latest"
                docker push "${{ env.DOCKER_HUB_USERNAME }}/${image}:latest"
              fi
            done
          fi


  create-release:
    needs: build-project
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          # `download-artifact` writes into the given path relative to the workspace root.
          # We set `path: dataset/artifacts` so subsequent `run` steps (which are executed
          # inside `dataset` due to defaults) can access the downloaded tar.xz archives with
          # `artifacts/**/*.tar.xz`.
          path: dataset/artifacts

      - name: List downloaded artifacts
        run: |
          echo "=== Downloaded artifacts ==="
          find artifacts -type f -name "*.tar.xz"

      - name: Unpack project artifacts
        run: |
          mkdir -p all_projects
          # Extract each project tar.xz archive into all_projects directory
          for archive in artifacts/**/*.tar.xz; do
            if [ -f "$archive" ]; then
              echo "Extracting $archive..."
              tar -xJf "$archive" -C all_projects/

              # After extracting each archive, delete unrelated directories (e.g. fuzz) from
              # the extracted project to reduce disk usage and avoid carrying over
              # e.g. AFL++ work/ directories from the combined archive.
              proj=$(basename "$archive" .tar.xz)
              if [ -d "all_projects/$proj" ]; then
                echo "Remove ./fuzz under all_projects/$proj ..."
                rm -rf "all_projects/$proj/fuzz" || true
              fi

            fi
          done

      - name: List all.tar.xz contents after cleanup
        run: |
          tree all_projects || true

      - name: Create all.tar.xz with all project contents
        id: create
        run: |
          # Compute short commit hash and prepare target directory so the resulting
          # archive extracts to a top-level directory named all-<short_sha>/
          SHORT_SHA=$(git -C .. rev-parse --short=8 "$GITHUB_SHA")
          TARGET_DIR="all-${SHORT_SHA}"
          ARCHIVE_NAME="${TARGET_DIR}.tar.xz"

          # Make sure we have a staging directory from the unpack step
          if [ ! -d all_projects ]; then
            echo "Error: all_projects directory not found - nothing to archive"
            exit 1
          fi

          # Move the extracted staging directory to the target directory so the
          # archive extracts to a single top-level folder named ${TARGET_DIR}/
          if [ -d "$TARGET_DIR" ]; then
            echo "Removing existing ${TARGET_DIR}"
            rm -rf "$TARGET_DIR"
          fi

          # Rename (move) the staging directory directly. This avoids copying and
          # keeps inode ownership and metadata where possible.
          mv all_projects "$TARGET_DIR" || {
            echo "Error: failed to move all_projects to ${TARGET_DIR}"
            exit 1
          }

          # Fail early if nothing was moved
          if [ -z "$(ls -A "$TARGET_DIR" 2>/dev/null)" ]; then
            echo "Error: ${TARGET_DIR} is empty after moving staging directory"
            exit 1
          fi

          # Archive the target directory itself so extraction produces a
          # single top-level folder (e.g. `all-<short>/`). Create the
          # archive in the current working directory (`dataset/`) â€” no
          # leading `../` is necessary because we do not cd into the
          # target directory.
          # Use maximum xz compression with multi-threading
          XZ_OPT="-9e -T0" tar -cJf "${ARCHIVE_NAME}" --exclude-vcs "${TARGET_DIR}"
          ls -lh "${ARCHIVE_NAME}"

          # Expose the archive name as a step output for later steps
          echo "all_archive=${ARCHIVE_NAME}" >> "$GITHUB_OUTPUT"

      - name: Upload artifact all.tar.xz
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.create.outputs.all_archive }}
          path: dataset/${{ steps.create.outputs.all_archive }}
          retention-days: 30

      - name: Delete existing release
        if: github.ref == format('refs/heads/{0}', github.event.repository.default_branch) && github.event_name != 'pull_request'
        run: |
          # Delete existing release and tag if they exist
          gh release delete latest --yes --cleanup-tag 2>/dev/null || true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Create release
        uses: softprops/action-gh-release@v2
        if: github.ref == format('refs/heads/{0}', github.event.repository.default_branch) && github.event_name != 'pull_request'
        with:
          tag_name: latest
          name: Latest Build
          body: |
            Automatically built artifacts from the main branch.

            ## Downloads

            - `${{ steps.create.outputs.all_archive }}` - All projects combined (unpacked contents, tar.xz format with maximum compression)
            - Individual project archives (e.g., `jq.tar.xz`, `sqlite.tar.xz`)

            ## Each project archive contains:
            - `bc/` - LLVM bitcode files for static analysis
            - `fuzz/` - AFL++ fuzzing binaries and resources (not included in all-xxx.tar.xz)

            ## Note:
            - Individual project archives (.tar.xz) contain both `bc/` and `fuzz/` directories
            - The combined `all-xxx.tar.xz` archive only contains `bc/` directories for all projects
          draft: false
          prerelease: false
          files: |
            # Files paths are relative to the workspace root; our created archives live under
            # `dataset/`, so reference them with the dataset prefix.
            dataset/${{ steps.create.outputs.all_archive }}
            dataset/artifacts/**/*.tar.xz
          make_latest: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
