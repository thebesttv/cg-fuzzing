name: Build Docker Images

on:
  push:
  workflow_dispatch:

env:
  DOCKER_HUB_USERNAME: thebesttv

# Permissions for artifacts and releases
permissions:
  contents: write

defaults:
  run:
    working-directory: ./dataset

jobs:
  find-projects:
    runs-on: ubuntu-latest
    outputs:
      projects: ${{ steps.find.outputs.projects }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Find projects with dockerfiles
        id: find
        run: |
          # Find all unique project directories containing any dockerfile
          # (bc.dockerfile, fuzz.dockerfile, cov.dockerfile, uftrace.dockerfile)
          projects=$(find . -maxdepth 2 -type f \( -name "bc.dockerfile" -o -name "fuzz.dockerfile" -o -name "cov.dockerfile" -o -name "uftrace.dockerfile" \) ! -path "./.git/*" \
            | xargs -I{} dirname {} \
            | sed 's|^\./||' \
            | sort -u \
            | jq -R -s -c 'split("\n") | map(select(length > 0))')

          echo "projects=${projects}" >> $GITHUB_OUTPUT
          echo "Found projects: ${projects}"

  get-changed-projects:
    needs: find-projects
    runs-on: ubuntu-latest
    outputs:
      projects: ${{ steps.set-projects.outputs.projects || steps.set-projects-pr.outputs.projects }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Detect changed dataset files
        id: changes
        uses: dorny/paths-filter@v3
        with:
          filters: |
            dataset:
              - 'dataset/**'
          list-files: json

      - name: Set projects for default branch
        id: set-projects
        if: github.ref == format('refs/heads/{0}', github.event.repository.default_branch)
        run: |
          echo "Default branch detected - running all projects"
          echo 'projects=${{ needs.find-projects.outputs.projects }}' >> $GITHUB_OUTPUT

      - name: Compute changed projects
        id: set-projects-pr
        if: github.ref != format('refs/heads/{0}', github.event.repository.default_branch)
        run: |
          set -euo pipefail
          FILES='${{ steps.changes.outputs.dataset_files }}'
          if [ -z "$FILES" ] || [ "$FILES" = "[]" ]; then
            echo "No dataset files changed"
            echo "projects=[]" >> $GITHUB_OUTPUT
            exit 0
          fi

          ALL='${{ needs.find-projects.outputs.projects }}'
          # Extract unique project names from changed dataset files
          CHANGED_PROJECTS=$(echo "$FILES" | jq -r '.[] | split("/")[1]' | sort -u)

          # Build final intersection between changed projects and projects that have dockerfiles
          RESULT_ARRAY=()
          for p in $CHANGED_PROJECTS; do
            if echo "$ALL" | jq -e --arg p "$p" 'index($p) // empty' >/dev/null 2>&1; then
              RESULT_ARRAY+=("$p")
            fi
          done

          if [ ${#RESULT_ARRAY[@]} -eq 0 ]; then
            echo "projects=[]" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Convert bash array to JSON array
          JSON=$(printf '%s\n' "${RESULT_ARRAY[@]}" | jq -R -s -c 'split("\n") | map(select(length > 0))')
          echo "projects=$JSON" >> $GITHUB_OUTPUT

  build-project:
    needs: get-changed-projects
    if: ${{ needs.get-changed-projects.outputs.projects != '[]' && needs.get-changed-projects.outputs.projects != 'null' }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        project: ${{ fromJson(needs.get-changed-projects.outputs.projects) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Validate project name
        run: |
          # Validate project name contains only safe characters
          if ! echo "${{ matrix.project }}" | grep -qE '^[a-zA-Z0-9_-]+$'; then
            echo "Error: Invalid project name: ${{ matrix.project }}"
            exit 1
          fi

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Create output directories
        run: |
          mkdir -p output/${{ matrix.project }}/{bc,fuzz}

      - name: Build bc.dockerfile (if exists)
        id: build-bc
        run: |
          if [ -f "${{ matrix.project }}/bc.dockerfile" ]; then
            echo "Building ${{ matrix.project }}-bc from ${{ matrix.project }}/bc.dockerfile"
            docker build \
              -f "${{ matrix.project }}/bc.dockerfile" \
              -t "${{ matrix.project }}-bc:latest" \
              .
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "bc.dockerfile not found for ${{ matrix.project }}"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Extract bc artifacts
        if: steps.build-bc.outputs.exists == 'true'
        run: |
          container_id=$(docker create "${{ matrix.project }}-bc:latest")
          # Copy bc files from container
          docker cp "$container_id:/home/SVF-tools/bc/." "output/${{ matrix.project }}/bc/" 2>/dev/null || true
          docker rm "$container_id"
          echo "=== bc artifacts ==="
          ls -la "output/${{ matrix.project }}/bc/" || true
          # Verify directory is non-empty
          if [ -z "$(ls -A "output/${{ matrix.project }}/bc/" 2>/dev/null)" ]; then
            echo "Error: bc artifacts directory is empty!"
            exit 1
          fi

      - name: Build fuzz.dockerfile (if exists)
        id: build-fuzz
        run: |
          if [ -f "${{ matrix.project }}/fuzz.dockerfile" ]; then
            echo "Building ${{ matrix.project }}-fuzz from ${{ matrix.project }}/fuzz.dockerfile"
            docker build \
              -f "${{ matrix.project }}/fuzz.dockerfile" \
              -t "${{ matrix.project }}-fuzz:latest" \
              .
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "fuzz.dockerfile not found for ${{ matrix.project }}"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Extract fuzz artifacts
        if: steps.build-fuzz.outputs.exists == 'true'
        run: |
          container_id=$(docker create "${{ matrix.project }}-fuzz:latest")
          # Copy fuzz binaries and resources from container
          docker cp "$container_id:/work/." "output/${{ matrix.project }}/fuzz/" 2>/dev/null || true
          docker rm "$container_id"
          echo "=== fuzz artifacts ==="
          ls -la "output/${{ matrix.project }}/fuzz/" || true
          # Verify directory is non-empty
          if [ -z "$(ls -A "output/${{ matrix.project }}/fuzz/" 2>/dev/null)" ]; then
            echo "Error: fuzz artifacts directory is empty!"
            exit 1
          fi

      - name: Build cov.dockerfile (if exists)
        id: build-cov
        run: |
          if [ -f "${{ matrix.project }}/cov.dockerfile" ]; then
            echo "Building ${{ matrix.project }}-cov from ${{ matrix.project }}/cov.dockerfile"
            docker build \
              -f "${{ matrix.project }}/cov.dockerfile" \
              -t "${{ matrix.project }}-cov:latest" \
              .
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "cov.dockerfile not found for ${{ matrix.project }}"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Build uftrace.dockerfile (if exists)
        id: build-uftrace
        run: |
          if [ -f "${{ matrix.project }}/uftrace.dockerfile" ]; then
            echo "Building ${{ matrix.project }}-uftrace from ${{ matrix.project }}/uftrace.dockerfile"
            docker build \
              -f "${{ matrix.project }}/uftrace.dockerfile" \
              -t "${{ matrix.project }}-uftrace:latest" \
              .
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "uftrace.dockerfile not found for ${{ matrix.project }}"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Remove empty directories
        run: |
          # Remove empty subdirectories from output
          find "output/${{ matrix.project }}" -type d -empty -delete 2>/dev/null || true
          echo "=== Final output structure ==="
          find "output/${{ matrix.project }}" -type f | head -50

      - name: Install 7z for compression
        run: |
          sudo apt-get update
          sudo apt-get install -y p7zip-full

      - name: Create project archive with 7z
        run: |
          cd output
          7z a -t7z -mx=9 -ms=on "${{ matrix.project }}.7z" "${{ matrix.project }}"
          ls -lh "${{ matrix.project }}.7z"

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.project }}
          # `defaults.run.working-directory` is `./dataset` so run steps create 7z archives under
          # `dataset/output/...`. Actions using `uses:` run from the workspace root, so
          # specify the dataset prefix so the uploader finds the file.
          path: dataset/output/${{ matrix.project }}.7z
          retention-days: 30

      - name: Login to Docker Hub
        if: github.ref == format('refs/heads/{0}', github.event.repository.default_branch) && github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          username: ${{ env.DOCKER_HUB_USERNAME }}
          password: ${{ secrets.DOCKER_HUB_TOKEN }}

      - name: Push Docker images to Docker Hub
        if: github.ref == format('refs/heads/{0}', github.event.repository.default_branch) && github.event_name != 'pull_request'
        run: |
          for type in bc fuzz cov uftrace; do
            image="${{ matrix.project }}-${type}"
            if docker image inspect "${image}:latest" >/dev/null 2>&1; then
              echo "Pushing ${{ env.DOCKER_HUB_USERNAME }}/${image}:latest"
              docker tag "${image}:latest" "${{ env.DOCKER_HUB_USERNAME }}/${image}:latest"
              docker push "${{ env.DOCKER_HUB_USERNAME }}/${image}:latest"
            fi
          done

  create-release:
    needs: build-project
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          # `download-artifact` writes into the given path relative to the workspace root.
          # We set `path: dataset/artifacts` so subsequent `run` steps (which are executed
          # inside `dataset` due to defaults) can access the downloaded 7z archives with
          # `artifacts/**/*.7z`.
          path: dataset/artifacts

      - name: List downloaded artifacts
        run: |
          echo "=== Downloaded artifacts ==="
          find artifacts -type f -name "*.7z"

      - name: Install 7z
        run: |
          sudo apt-get update
          sudo apt-get install -y p7zip-full

      - name: Unpack project artifacts
        run: |
          mkdir -p all_projects
          # Extract each project 7z archive into all_projects directory
          for archive in artifacts/**/*.7z; do
            if [ -f "$archive" ]; then
              echo "Extracting $archive..."
              7z x "$archive" -oall_projects/ -aoa

              # After extracting each archive, delete unrelated directories (e.g. fuzz) from
              # the extracted project to reduce disk usage and avoid carrying over
              # e.g. AFL++ work/ directories from the combined archive.
              proj=$(basename "$archive" .7z)
              if [ -d "all_projects/$proj" ]; then
                echo "Remove ./fuzz under all_projects/$proj ..."
                rm -rfv "all_projects/$proj/fuzz" || true
              fi

            fi
          done

      - name: List all.7z contents after cleanup
        run: |
          tree all_projects || true

      - name: Create all.7z with all project contents
        id: create
        run: |
          # Compute short commit hash and prepare target directory so the resulting
          # archive extracts to a top-level directory named all-<short_sha>/
          SHORT_SHA=$(git -C .. rev-parse --short=8 "$GITHUB_SHA")
          TARGET_DIR="all-${SHORT_SHA}"
          ARCHIVE_NAME="${TARGET_DIR}.7z"

          # Make sure we have a staging directory from the unpack step
          if [ ! -d all_projects ]; then
            echo "Error: all_projects directory not found - nothing to archive"
            exit 1
          fi

          # Move the extracted staging directory to the target directory so the
          # archive extracts to a single top-level folder named ${TARGET_DIR}/
          if [ -d "$TARGET_DIR" ]; then
            echo "Removing existing ${TARGET_DIR}"
            rm -rf "$TARGET_DIR"
          fi

          # Rename (move) the staging directory directly. This avoids copying and
          # keeps inode ownership and metadata where possible.
          mv all_projects "$TARGET_DIR" || {
            echo "Error: failed to move all_projects to ${TARGET_DIR}"
            exit 1
          }

          # Fail early if nothing was moved
          if [ -z "$(ls -A "$TARGET_DIR" 2>/dev/null)" ]; then
            echo "Error: ${TARGET_DIR} is empty after moving staging directory"
            exit 1
          fi

          # Archive the target directory itself so extraction produces a
          # single top-level folder (e.g. `all-<short>/`). Create the
          # archive in the current working directory (`dataset/`) â€” no
          # leading `../` is necessary because we do not cd into the
          # target directory.
          7z a -t7z -mx=9 -ms=on "${ARCHIVE_NAME}" "${TARGET_DIR}"
          ls -lh "${ARCHIVE_NAME}"

          # Expose the archive name as a step output for later steps
          echo "all_archive=${ARCHIVE_NAME}" >> "$GITHUB_OUTPUT"

      - name: Upload artifact all.7z
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.create.outputs.all_archive }}
          path: dataset/${{ steps.create.outputs.all_archive }}
          retention-days: 30

      - name: Delete existing release
        if: github.ref == format('refs/heads/{0}', github.event.repository.default_branch) && github.event_name != 'pull_request'
        run: |
          # Delete existing release and tag if they exist
          gh release delete latest --yes --cleanup-tag 2>/dev/null || true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Create release
        uses: softprops/action-gh-release@v2
        if: github.ref == format('refs/heads/{0}', github.event.repository.default_branch) && github.event_name != 'pull_request'
        with:
          tag_name: latest
          name: Latest Build
          body: |
            Automatically built artifacts from the main branch.

            ## Downloads

            - `${{ steps.create.outputs.all_archive }}` - All projects combined (unpacked contents, 7z format with maximum compression)
            - Individual project archives (e.g., `jq.7z`, `sqlite.7z`)

            ## Each project archive contains:
            - `bc/` - LLVM bitcode files for static analysis
            - `fuzz/` - AFL++ fuzzing binaries and resources (not included in all-xxx.7z)

            ## Note:
            - Individual project archives (.7z) contain both `bc/` and `fuzz/` directories
            - The combined `all-xxx.7z` archive only contains `bc/` directories for all projects
          draft: false
          prerelease: false
          files: |
            # Files paths are relative to the workspace root; our created archives live under
            # `dataset/`, so reference them with the dataset prefix.
            dataset/${{ steps.create.outputs.all_archive }}
            dataset/artifacts/**/*.7z
          make_latest: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
